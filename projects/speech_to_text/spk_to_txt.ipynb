{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b314ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am listening...\n",
      "Listening...\n",
      "You said: sorry my Tails any\n",
      "Text from get audio: sorry my tails any\n",
      "I am listening...\n",
      "Listening...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 115\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    114\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mI am listening...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     text = \u001b[43mget_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m     respond(text)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mget_audio\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     21\u001b[39m r.adjust_for_ambient_noise(source, duration=\u001b[32m1\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mListening...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m audio = \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m said = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Github Projects\\research_MLs\\ml_env\\Lib\\site-packages\\speech_recognition\\__init__.py:460\u001b[39m, in \u001b[36mRecognizer.listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    458\u001b[39m result = \u001b[38;5;28mself\u001b[39m._listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Github Projects\\research_MLs\\ml_env\\Lib\\site-packages\\speech_recognition\\__init__.py:492\u001b[39m, in \u001b[36mRecognizer._listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m elapsed_time > timeout:\n\u001b[32m    490\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WaitTimeoutError(\u001b[33m\"\u001b[39m\u001b[33mlistening timed out while waiting for phrase to start\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m buffer = \u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) == \u001b[32m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[32m    494\u001b[39m frames.append(buffer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Github Projects\\research_MLs\\ml_env\\Lib\\site-packages\\speech_recognition\\__init__.py:191\u001b[39m, in \u001b[36mMicrophone.MicrophoneStream.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpyaudio_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Github Projects\\research_MLs\\ml_env\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[39m, in \u001b[36mPyAudio.Stream.read\u001b[39m\u001b[34m(self, num_frames, exception_on_overflow)\u001b[39m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_input:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot input stream\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    569\u001b[39m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#import section\n",
    "\n",
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pygame\n",
    "import pyjokes\n",
    "import wikipedia\n",
    "import pyaudio\n",
    "import webbrowser\n",
    "import winshell\n",
    "from pygame import mixer\n",
    "\n",
    "#get mic audio\n",
    "def get_audio():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        r.pause_threshold = 1\n",
    "        # Ajuste do reconhecimento para o ambiente\n",
    "        r.adjust_for_ambient_noise(source, duration=1)\n",
    "        print(\"Listening...\")\n",
    "        audio = r.listen(source)\n",
    "        said = \"\"\n",
    "        try:\n",
    "            said = r.recognize_google(audio)\n",
    "            print(f\"You said: {said}\")\n",
    "        except sr.UnknownValueError:\n",
    "            speak(\"Sorry, I did not get that.\")\n",
    "        except sr.RequestError:\n",
    "            speak(\"Sorry, the service is not available\")\n",
    "    return said.lower()\n",
    "\n",
    "# Speak converted audio to text\n",
    "def speak(text):\n",
    "    tts = gTTS(text=text, lang='en')\n",
    "    filename = \"voice.mp3\"\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except OSError:\n",
    "        pass\n",
    "    tts.save(filename)\n",
    "\n",
    "    # Usando o pygame para tocar o áudio\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(filename)\n",
    "    pygame.mixer.music.play()\n",
    "    while pygame.mixer.music.get_busy():  # Aguarda até que o áudio termine\n",
    "        pygame.time.Clock().tick(10)\n",
    "\n",
    "# Function to respond to commands\n",
    "def respond(text):\n",
    "    print(\"Text from get audio: \" + text)\n",
    "    if 'youtube' in text:\n",
    "        speak(\"What do you want to search for?\")\n",
    "        keyword = get_audio()\n",
    "        if keyword != '':\n",
    "            url = f\"https://www.youtube.com/results?search_query={keyword}\"\n",
    "            webbrowser.get().open(url)\n",
    "            speak(f\"Here is what I have found for {keyword} on YouTube.\")\n",
    "    elif 'search' in text:\n",
    "        speak(\"What do you want to search for?\")\n",
    "        query = get_audio()\n",
    "        if query != '':\n",
    "            try:\n",
    "                result = wikipedia.summary(query, sentences=3)\n",
    "                speak(\"According to Wikipedia\")\n",
    "                print(result)\n",
    "                speak(result)\n",
    "            except wikipedia.exceptions.DisambiguationError as e:\n",
    "                speak(\"There were multiple results. Please be more specific.\")\n",
    "            except wikipedia.exceptions.HTTPTimeoutError:\n",
    "                speak(\"I'm having trouble connecting to Wikipedia.\")\n",
    "    elif 'joke' in text:\n",
    "        speak(pyjokes.get_joke())\n",
    "    elif 'empty recycle bin' in text:\n",
    "        winshell.recycle_bin().empty(confirm=False, show_progress=False, sound=True)\n",
    "        speak(\"Recycle bin emptied.\")\n",
    "    elif 'what time' in text:\n",
    "        strTime = datetime.today().strftime(\"%H:%M %p\")\n",
    "        print(strTime)\n",
    "        speak(strTime)\n",
    "    elif 'play music' in text or 'play song' in text:\n",
    "        speak(\"Now playing...\")\n",
    "        music_dir = \"C:\\\\Users\\\\UserName\\\\Downloads\\\\Music\\\\\"  # Customize this directory to your system\n",
    "        try:\n",
    "            songs = os.listdir(music_dir)\n",
    "            if songs:\n",
    "                print(songs)\n",
    "                playmusic(music_dir + \"\\\\\" + songs[0])\n",
    "            else:\n",
    "                speak(\"No songs found in the directory.\")\n",
    "        except FileNotFoundError:\n",
    "            speak(\"Music directory not found.\")\n",
    "    elif 'stop music' in text:\n",
    "        speak(\"Stopping playback.\")\n",
    "        stopmusic()\n",
    "    elif 'exit' in text:\n",
    "        speak(\"Goodbye, till next time.\")\n",
    "        exit()\n",
    "\n",
    "# Play music\n",
    "def playmusic(song):\n",
    "    mixer.init()\n",
    "    mixer.music.load(song)\n",
    "    mixer.music.play()\n",
    "\n",
    "# Stop music\n",
    "def stopmusic():\n",
    "    mixer.music.stop()\n",
    "\n",
    "# Main loop: Listening and responding to commands\n",
    "while True:\n",
    "    print(\"I am listening...\")\n",
    "    text = get_audio()\n",
    "    respond(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8685293e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
