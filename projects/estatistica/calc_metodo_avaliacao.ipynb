{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d6cb227-ae2e-4ae8-b639-22216590e617",
   "metadata": {},
   "source": [
    "# C√°lculo de M√©tricas de Avalia√ß√£o de \n",
    "Ao treinar modelos de classifica√ß√£o em Machine Learning, n√£o basta apenas saber quantas previs√µes o modelo acertou. √â importante entender como ele acertou e onde ele errou ‚Äî principalmente quando se trata de problemas mais delicados, como diagn√≥sticos m√©dicos, detec√ß√£o de fraudes ou sistemas de seguran√ßa.\n",
    "\n",
    "Para isso, usamos m√©tricas de avalia√ß√£o, que nos ajudam a analisar o desempenho do modelo com mais profundidade. No caso de classifica√ß√£o bin√°ria (onde s√≥ existem duas classes poss√≠veis, como ‚Äúpositivo‚Äù e ‚Äúnegativo‚Äù), a base para todas essas m√©tricas √© a matriz de confus√£o.\n",
    "\n",
    "üßæ A Matriz de Confus√£o\n",
    "A matriz de confus√£o √© uma tabela que compara as previs√µes do modelo com os valores reais. Ela √© organizada assim:\n",
    "\n",
    "|                   | Previsto Positivo            | Previsto Negativo            |\n",
    "| ----------------- | ---------------------------- | ---------------------------- |\n",
    "| **Real Positivo** | **VP** (Verdadeiro Positivo) | **FN** (Falso Negativo)      |\n",
    "| **Real Negativo** | **FP** (Falso Positivo)      | **VN** (Verdadeiro Negativo) |\n",
    "\n",
    "\n",
    "### O que cada elemento significa?\n",
    "\n",
    "- **VP (Verdadeiro Positivo)**: o modelo previu \"positivo\" e estava certo.\n",
    "\n",
    "- **FN (Falso Negativo)**: o modelo previu \"negativo\", mas era \"positivo\".\n",
    "\n",
    "- **FP (Falso Positivo)**: o modelo previu \"positivo\", mas era \"negativo\".\n",
    "\n",
    "- **VN (Verdadeiro Negativo)**: o modelo previu \"negativo\" e estava certo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d9836f-eb68-4eda-9432-8bc8229c9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import numpy as np\n",
    "\n",
    "# Fun√ß√µes para c√°lculo das m√©tricas\n",
    "def calcular_acuracia(VP, VN, FP, FN):\n",
    "    return (VP + VN) / (VP + VN + FP + FN)\n",
    "\n",
    "def calcular_precisao(VP, FP):\n",
    "    return VP / (VP + FP) if (VP + FP) != 0 else 0\n",
    "\n",
    "def calcular_sensibilidade(VP, FN):  # Tamb√©m chamada de Recall\n",
    "    return VP / (VP + FN) if (VP + FN) != 0 else 0\n",
    "\n",
    "def calcular_especificidade(VN, FP):\n",
    "    return VN / (VN + FP) if (VN + FP) != 0 else 0\n",
    "\n",
    "def calcular_f_score(precisao, sensibilidade):\n",
    "    return 2 * (precisao * sensibilidade) / (precisao + sensibilidade) if (precisao + sensibilidade) != 0 else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64637483-8195-4705-b714-1eab8edb6b41",
   "metadata": {},
   "source": [
    "## Matriz de Confus√£o Fict√≠cia\n",
    "Vamos usar a seguinte matriz de confus√£o arbitr√°ria para os c√°lculos:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a60f40-2647-4a03-8298-c7057cf9c13f",
   "metadata": {},
   "source": [
    "|                          | **Classe Positiva Prevista** | **Classe Negativa Prevista** |\n",
    "| ------------------------ | ---------------------------- | ---------------------------- |\n",
    "| **Classe Positiva Real** | VP = 70                      | FN = 30                      |\n",
    "| **Classe Negativa Real** | FP = 10                      | VN = 90                      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37e9c8c5-1c6a-4fed-8bf0-29dd064acd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atribuindo os valores\n",
    "VP = 70\n",
    "FN = 30\n",
    "FP = 10\n",
    "VN = 90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf2b19e-6db7-48fb-a6e3-f790c8537b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia: 0.80\n",
      "Precis√£o: 0.88\n",
      "Sensibilidade (Recall): 0.70\n",
      "Especificidade: 0.90\n",
      "F-Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "acuracia = calcular_acuracia(VP, VN, FP, FN)\n",
    "precisao = calcular_precisao(VP, FP)\n",
    "sensibilidade = calcular_sensibilidade(VP, FN)\n",
    "especificidade = calcular_especificidade(VN, FP)\n",
    "f_score = calcular_f_score(precisao, sensibilidade)\n",
    "\n",
    "# Exibindo os resultados\n",
    "print(f\"Acur√°cia: {acuracia:.2f}\")\n",
    "print(f\"Precis√£o: {precisao:.2f}\")\n",
    "print(f\"Sensibilidade (Recall): {sensibilidade:.2f}\")\n",
    "print(f\"Especificidade: {especificidade:.2f}\")\n",
    "print(f\"F-Score: {f_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64365dea-e3d5-4353-b029-a786ce4bef07",
   "metadata": {},
   "source": [
    "### O que cada elemento significa?\n",
    "- VP (Verdadeiro Positivo): o modelo previu **\"positivo\"** e estava certo.\n",
    "\n",
    "- FN (Falso Negativo): o modelo previu **\"negativo\"**, mas era \"positivo\".\n",
    "\n",
    "- FP (Falso Positivo): o modelo previu **\"positivo\"**, mas era \"negativo\".\n",
    "\n",
    "- VN (Verdadeiro Negativo): o modelo previu **\"negativo\"** e estava certo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
