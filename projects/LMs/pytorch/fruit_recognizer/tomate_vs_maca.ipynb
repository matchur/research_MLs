{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a330e2cf-1e64-4d00-a696-b335e742387a",
   "metadata": {},
   "source": [
    "Olá, nesse notebook a idéia é, utilizando o PyTorch, resolver um problema de classificação de imagens de tomates e maçãs. \n",
    "O dataset utilizado é o Apples or Tomatoes obtido no Kaggle.\n",
    "\n",
    "Para começar, vamos importar as bibliotecas necessárias e carregar o dataset.\n",
    "Certifique-se de já ter rodado o pip install requirements.txt do dir root desse projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f95248-d88b-4896-b09b-177a6d6b9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1f0e8-3ece-4ec2-9254-0526297503fa",
   "metadata": {},
   "source": [
    "No PyTorch se utiliza **Transforms** para pré-processar imagens. \n",
    "\n",
    "O transforms no PyTorch faz parte do *torchvision.transforms*, que é um módulo responsável por pré-processar imagens antes de passá-las para um modelo de deep learning. Ele é essencial para normalização, redimensionamento e aumento de dados (data augmentation).\n",
    "\n",
    "**Os modelos de deep learning convergem mais rápido se os valores dos pixels forem normalizados.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b909b78f-5c10-441b-8b3f-59ed49bf9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das transformações para normalizar e aumentar os dados\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),  # Redimensionar para tamanho fixo\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee44768-e168-4fb9-b00c-55f6b0dc4cb2",
   "metadata": {},
   "source": [
    "Agora vamos definir o caminho de diretório das imagens, e em seguida, vincular eles com o transform.\n",
    "\n",
    "Após feita a vinculação vamos verificar as classes que foram criadas a partir dos arquivos, \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95fd06ff-8e2a-4eed-bac4-34dec10d31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretórios das imagens - Caminho Absoluto\n",
    "train_dir = \"C:\\\\Users\\\\Matheus\\\\Documents\\\\Github Projects\\\\research_MLs\\\\projects\\\\LMs\\\\dataset\\\\tomatoes_vs_apples\\\\train\"\n",
    "test_dir = \"C:\\\\Users\\\\Matheus\\\\Documents\\\\Github Projects\\\\research_MLs\\\\projects\\\\LMs\\\\dataset\\\\tomatoes_vs_apples\\\\test\"\n",
    "\n",
    "# Carregamento dos datasets\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Verificando classes\n",
    "print(\"Classes de Treino: \",train_dataset.class_to_idx)\n",
    "print(\"Classes de Teste: \",test_dataset.class_to_idx)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4958a9e-3307-42b5-92d4-1bbd0b18f907",
   "metadata": {},
   "source": [
    "Após isso vamos criar os **DataLoaders** para carregar os dados e separar em lotes.\n",
    "\n",
    "O DataLoader é uma classe em PyTorch que cuida de carregar os dados e fornecer lotes de amostras durante o treinamento de um modelo. Ele divide os dados em batches (lotes) e permite que o treinamento seja feito em pedaços menores, em vez de carregar toda a base de dados de uma vez.\n",
    "\n",
    "- *batch_size*: Define o número de amostras processadas em cada passo de treinamento. Exemplo: 32 imagens por vez.\n",
    "\n",
    "- *shuffle*: Se for True, embaralha os dados a cada época de treinamento para garantir que o modelo não aprenda padrões artificiais pela ordem dos dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d6ab74-83af-4b29-ba64-8c9dd3c9ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataLoaders para treinar em batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
