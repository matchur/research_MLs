{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a330e2cf-1e64-4d00-a696-b335e742387a",
   "metadata": {},
   "source": [
    "Olá, nesse notebook a idéia é, utilizando o PyTorch, resolver um problema de classificação de imagens de tomates e maçãs. \n",
    "O dataset utilizado é o Apples or Tomatoes obtido no Kaggle.\n",
    "\n",
    "Para começar, vamos importar as bibliotecas necessárias e carregar o dataset.\n",
    "Certifique-se de já ter rodado o pip install requirements.txt do dir root desse projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f95248-d88b-4896-b09b-177a6d6b9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1f0e8-3ece-4ec2-9254-0526297503fa",
   "metadata": {},
   "source": [
    "No PyTorch se utiliza **Transforms** para pré-processar imagens. \n",
    "\n",
    "O transforms no PyTorch faz parte do *torchvision.transforms*, que é um módulo responsável por pré-processar imagens antes de passá-las para um modelo de deep learning. Ele é essencial para normalização, redimensionamento e aumento de dados (data augmentation).\n",
    "\n",
    "**Os modelos de deep learning convergem mais rápido se os valores dos pixels forem normalizados.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b909b78f-5c10-441b-8b3f-59ed49bf9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das transformações para normalizar e aumentar os dados\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),  # Redimensionar para tamanho fixo\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee44768-e168-4fb9-b00c-55f6b0dc4cb2",
   "metadata": {},
   "source": [
    "Agora vamos definir o caminho de diretório das imagens, e em seguida, vincular eles com o transform.\n",
    "\n",
    "Feita a vinculação vamos verificar as **Classes** que foram criadas, ele separa as classes a partir do nome do diretório, então é importante que as imagens estejam organizadas em pastas com o nome da classe de cada objeto correspondente.\n",
    "\n",
    "Para verificar, vamos dar um *print* no *train_dataset* e no *test_dataset*, a saída deve ser:\n",
    "\n",
    "Classes de Treino:  {'apples': 0, 'tomatoes': 1}\\\n",
    "Classes de Teste:  {'apples': 0, 'tomatoes': 1}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95fd06ff-8e2a-4eed-bac4-34dec10d31b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes de Treino:  {'apples': 0, 'tomatoes': 1}\n",
      "Classes de Teste:  {'apples': 0, 'tomatoes': 1}\n"
     ]
    }
   ],
   "source": [
    "# Diretórios das imagens - Caminho Absoluto\n",
    "train_dir = \"C:\\\\Users\\\\Matheus\\\\Documents\\\\Github Projects\\\\research_MLs\\\\projects\\\\LMs\\\\dataset\\\\tomatoes_vs_apples\\\\train\"\n",
    "test_dir = \"C:\\\\Users\\\\Matheus\\\\Documents\\\\Github Projects\\\\research_MLs\\\\projects\\\\LMs\\\\dataset\\\\tomatoes_vs_apples\\\\test\"\n",
    "\n",
    "# Carregamento dos datasets\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Verificando classes\n",
    "print(\"Classes de Treino: \",train_dataset.class_to_idx)\n",
    "print(\"Classes de Teste: \",test_dataset.class_to_idx)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4958a9e-3307-42b5-92d4-1bbd0b18f907",
   "metadata": {},
   "source": [
    "Após isso vamos criar os **DataLoaders** para carregar os dados e separar em lotes.\n",
    "\n",
    "O DataLoader é uma classe em PyTorch que cuida de carregar os dados e fornecer lotes de amostras durante o treinamento de um modelo. Ele divide os dados em batches (lotes) e permite que o treinamento seja feito em pedaços menores, em vez de carregar toda a base de dados de uma vez.\n",
    "\n",
    "- *batch_size*: Define o número de amostras processadas em cada passo de treinamento. Exemplo: 32 imagens por vez.\n",
    "\n",
    "- *shuffle*: Se for True, embaralha os dados a cada época de treinamento para garantir que o modelo não aprenda padrões artificiais pela ordem dos dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2d6ab74-83af-4b29-ba64-8c9dd3c9ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataLoaders para treinar em batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea7ad0a-1be3-4097-82c0-234609eede89",
   "metadata": {},
   "source": [
    "Agora vamos definir uma **rede neural convolucional** usando **torch.nn**. \n",
    "\n",
    "As **camadas convolucionais** são um dos componentes fundamentais das redes neurais convolucionais (CNNs), que são amplamente usadas em tarefas de visão computacional, como reconhecimento de imagens, detecção de objetos, e segmentação de imagens. Elas têm a função principal de extrair características ou padrões das imagens, como bordas, texturas e formas, para ajudar o modelo a entender os objetos ou os contextos dentro de uma imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36eb407e-1fe4-4c0c-a5d6-23429f7cfeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TomatoVsAppleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TomatoVsAppleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 18 * 18, 128)  # Ajustar o tamanho dependendo do tamanho final\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 1)  # Saída binária\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))  # Saída entre 0 e 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0520fd9f-6cd5-426c-a381-205e532fd32a",
   "metadata": {},
   "source": [
    "Agora, vamos configurar o treinamento. \n",
    "\n",
    "Caso a máquina que esteja rodando tenha uma placa de vídeo Nvidia e ela tem suporte a processamento CUDA, então vamos usar o **torch.cuda.is_available()** caso contrario vamos usar a CPU.\n",
    "\n",
    "Para fazer o modelo, aplicamos a função de convolução ao dispositivo (no meu caso CUDA).\n",
    "\n",
    "Definimos a função de perda e o otimizador.\n",
    "Como temos uma saída binária, usamos de critério o Binary Cross Entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f57d8e51-d8a0-4aa6-8112-ff5957e0319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TomatoVsAppleCNN().to(device)\n",
    "\n",
    "# Função de perda e otimizador\n",
    "criterion = nn.BCELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a18cf17-73ee-4290-8878-4efe545c342f",
   "metadata": {},
   "source": [
    "Agora vem a parte divertida, treinar o modelo!\n",
    "\n",
    "Vamos definir a quantidade de épocas dele, ou seja a quantidade de vezes que o modelo vai passar pelos dados e ajustar o peso de cada um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3c98993-efb7-426d-a2e8-f6929f43afc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época [1/10], Perda: 0.7533, Acurácia: 53.40%\n",
      "Época [2/10], Perda: 0.6547, Acurácia: 61.22%\n",
      "Época [3/10], Perda: 0.6276, Acurácia: 67.35%\n",
      "Época [4/10], Perda: 0.5789, Acurácia: 70.07%\n",
      "Época [5/10], Perda: 0.5725, Acurácia: 69.39%\n",
      "Época [6/10], Perda: 0.5905, Acurácia: 71.43%\n",
      "Época [7/10], Perda: 0.5696, Acurácia: 68.37%\n",
      "Época [8/10], Perda: 0.6190, Acurácia: 71.09%\n",
      "Época [9/10], Perda: 0.6094, Acurácia: 68.37%\n",
      "Época [10/10], Perda: 0.5707, Acurácia: 72.11%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device, dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Época [{epoch+1}/{num_epochs}], Perda: {running_loss/len(train_loader):.4f}, Acurácia: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd99be4-9a22-4821-bdc0-5e9a60ed0f73",
   "metadata": {},
   "source": [
    "Veja que em cada Época, o treinamento foi se aprimorando e algumas vezes foi retrocedendo, isso ocorre porque os pesos foram sendo estabelecidos automaticamente pelo algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec28e0e-cbef-4ff5-8390-16c108d09e8e",
   "metadata": {},
   "source": [
    "Após o treinamento, precisamos medir o desempenho do modelo para garantir que ele generaliza bem para novas imagens. Para isso, utilizamos o conjunto de teste e calculamos métricas como acurácia, precisão, recall e F1-score.\n",
    "\n",
    "A avaliação nos permite verificar quão bem o modelo diferencia maçãs de tomates e identificar possíveis problemas, como overfitting (quando o modelo memoriza os dados de treino e não generaliza bem para novos dados)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d429eeac-3e4b-490e-a5cc-d68d9438c25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 70.10%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device, dtype=torch.float32)\n",
    "        outputs = model(images).squeeze()\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Acurácia no conjunto de teste: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3803c4dc-0ce8-4ec6-b0c0-868c6c77c97c",
   "metadata": {},
   "source": [
    "Caso queira o relatório completo, faça:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c48860-9e47-4140-9026-62fef13a3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device, dtype=torch.float32)\n",
    "        outputs = model(images).squeeze()  # Obtém as previsões\n",
    "        predictions = (outputs > 0.5).float()  # Converte probabilidades para 0 ou 1\n",
    "        \n",
    "        all_predictions.extend(predictions.cpu().numpy())  # Salva previsões\n",
    "        all_labels.extend(labels.cpu().numpy())  # Salva rótulos reais\n",
    "\n",
    "accuracy = (sum(1 for p, l in zip(all_predictions, all_labels) if p == l) / len(all_labels)) * 100\n",
    "precision = precision_score(all_labels, all_predictions)\n",
    "recall = recall_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "print(f\"Acurácia: {accuracy:.2f}%\")\n",
    "print(f\"Precisão: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070d8457-e865-4b94-975a-49e94c9278d3",
   "metadata": {},
   "source": [
    "Agora, vamos testar com uma imagem aleatória na internet e ver se nosso modelo está bem treinado para essa função. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "226685f5-6e43-4355-9fc6-393a4701fb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predição: Maçã (Confiança: 0.36)\n",
      "Predição: Tomate (Confiança: 0.62)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def predict_image(img_path, model):\n",
    "    model.eval()\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((150, 150)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img).squeeze().item()\n",
    "        class_label = \"Tomate\" if output > 0.5 else \"Maçã\"\n",
    "        print(f\"Predição: {class_label} (Confiança: {output:.2f})\")\n",
    "\n",
    "# Exemplo de uso:\n",
    "predict_image(\"C:\\\\Users\\\\Matheus\\\\Documents\\\\Github Projects\\\\research_MLs\\\\projects\\\\LMs\\\\dataset\\\\tomatoes_vs_apples\\\\test\\\\apples\\\\img_p1_84.jpeg\", model)\n",
    "predict_image(\"C:\\\\Users\\\\Matheus\\\\Documents\\\\Github Projects\\\\research_MLs\\\\projects\\\\LMs\\\\dataset\\\\tomatoes_vs_apples\\\\test\\\\apples\\\\img_p3_86.jpeg\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d97ee2-0e83-42e1-b032-ec1b3a3105ae",
   "metadata": {},
   "source": [
    "Aparentemente, nosso modelo não está bem treinado... talvez um FineTunning resolva esse problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c7ba74-6281-4bfe-84f2-ed66de817a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
