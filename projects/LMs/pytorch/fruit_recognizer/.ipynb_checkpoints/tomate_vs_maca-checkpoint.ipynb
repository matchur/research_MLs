{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a330e2cf-1e64-4d00-a696-b335e742387a",
   "metadata": {},
   "source": [
    "Olá, nesse notebook a idéia é, utilizando o PyTorch, resolver um problema de classificação de imagens de tomates e maçãs. \n",
    "O dataset utilizado é o Apples or Tomatoes obtido no Kaggle.\n",
    "\n",
    "Para começar, vamos importar as bibliotecas necessárias e carregar o dataset.\n",
    "Certifique-se de já ter rodado o pip install requirements.txt do dir root desse projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f95248-d88b-4896-b09b-177a6d6b9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1f0e8-3ece-4ec2-9254-0526297503fa",
   "metadata": {},
   "source": [
    "No PyTorch se utiliza **Transforms** para pré-processar imagens. \n",
    "\n",
    "O transforms no PyTorch faz parte do *torchvision.transforms*, que é um módulo responsável por pré-processar imagens antes de passá-las para um modelo de deep learning. Ele é essencial para normalização, redimensionamento e aumento de dados (data augmentation).\n",
    "\n",
    "**Os modelos de deep learning convergem mais rápido se os valores dos pixels forem normalizados.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b909b78f-5c10-441b-8b3f-59ed49bf9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição das transformações para normalizar e aumentar os dados\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),  # Redimensionar para tamanho fixo\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee44768-e168-4fb9-b00c-55f6b0dc4cb2",
   "metadata": {},
   "source": [
    "Agora vamos definir o caminho de diretório das imagens, e em seguida, vincular eles com o transform.\n",
    "\n",
    "Após isso vamos criar os **DataLoaders** para carregar os dados e separar em lotes.\n",
    "\n",
    "O DataLoader é uma classe em PyTorch que cuida de carregar os dados e fornecer lotes de amostras durante o treinamento de um modelo. Ele divide os dados em batches (lotes) e permite que o treinamento seja feito em pedaços menores, em vez de carregar toda a base de dados de uma vez.\n",
    "\n",
    "- *batch_size*: Define o número de amostras processadas em cada passo de treinamento. Exemplo: 32 imagens por vez.\n",
    "\n",
    "- *shuffle*: Se for True, embaralha os dados a cada época de treinamento para garantir que o modelo não aprenda padrões artificiais pela ordem dos dados.\n",
    "\n",
    "Agora vamos verificar as classes que foram criadas a partir dos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95fd06ff-8e2a-4eed-bac4-34dec10d31b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"dict\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m test_loader = DataLoader(test_dataset, batch_size=\u001b[32m32\u001b[39m, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Verificando classes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33;43m\"\u001b[39;49m\u001b[33;43mClasses de Treino: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m+\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclass_to_idx\u001b[49m)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mClasses de Teste: \u001b[39m\u001b[33m\"\u001b[39m+test_dataset.class_to_idx)\n",
      "\u001b[31mTypeError\u001b[39m: can only concatenate str (not \"dict\") to str"
     ]
    }
   ],
   "source": [
    "# Diretórios das imagens - Caminho Absoluto\n",
    "train_dir = \"C:\\\\Users\\\\Matheus\\\\Documents\\\\Github Projects\\\\research_MLs\\\\projects\\\\LMs\\\\dataset\\\\tomatoes_vs_apples\\\\train\"\n",
    "test_dir = \"C:\\\\Users\\\\Matheus\\\\Documents\\\\Github Projects\\\\research_MLs\\\\projects\\\\LMs\\\\dataset\\\\tomatoes_vs_apples\\\\test\"\n",
    "\n",
    "# Carregamento dos datasets\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Criar DataLoaders para treinar em batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Verificando classes\n",
    "print(\"Classes de Treino: \",train_dataset.class_to_idx)\n",
    "print(\"Classes de Teste: \",test_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d6ab74-83af-4b29-ba64-8c9dd3c9ceeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
